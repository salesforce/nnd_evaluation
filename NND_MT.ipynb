{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will use GPU: 1\n"
     ]
    }
   ],
   "source": [
    "import utils_misc\n",
    "freer_gpu = utils_misc.select_freer_gpu()\n",
    "\n",
    "from utils_nnd_dataset import load_mt_mqm_nnd\n",
    "from utils_nnd import run_nnd, GeneratorHF\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gens = [\n",
    "        {\"model_name\": \"T5 Large\", \"model_params\": {\"model_card\": \"t5-large\", \"force_dec_prepend\": \"translate English to German:\"}},\n",
    "        {\"model_name\": \"FSMT WMT19 En-De\", \"model_params\": {\"model_card\": \"facebook/wmt19-en-de\"}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-07 12:52:17,554] [WARNING] [partition_parameters.py:53:<module>] unable to find torch.distributed._all_gather_base. will fall back to torch.distributed.all_gather which will result in suboptimal performance. please consider upgrading your pytorch installation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/anaconda3/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "NND T5 Large: 100%|██████████| 42675/42675 [17:21<00:00, 40.97it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'T5 Large', 'accuracy': 49.35442296426479, 'A_No-error': 0.49354422964264794, 'A_Fluency/Punctuation': 0.4889820197377315, 'A_Style/Awkward': 0.49395313681027964, 'A_Accuracy/Mistranslation': 0.4800846896916766, 'A_Terminology/Inappropriate for context': 0.4923398328690808, 'A_Fluency/Grammar': 0.5133703997881918, 'A_Fluency/Inconsistency': 0.4070278184480234, 'A_Fluency/Spelling': 0.65625, 'A_Accuracy/Untranslated text': 0.46153846153846156, 'A_Accuracy/Addition': 0.6168224299065421, 'A_Fluency/Register': 0.3870967741935484, 'A_Terminology/Inconsistent use of terminology': 0.31034482758620685, 'A_Fluency/Display': 0.7608695652173914, 'A_Locale convention/Currency format': 0.2564102564102564, 'A_Locale convention/Date format': 0.9230769230769231, 'A_Locale convention/Time format': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NND FSMT WMT19 En-De: 100%|██████████| 42675/42675 [04:04<00:00, 174.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'FSMT WMT19 En-De', 'accuracy': 51.606326889279444, 'A_No-error': 0.5160632688927944, 'A_Style/Awkward': 0.5026455026455027, 'A_Accuracy/Mistranslation': 0.4751885668916237, 'A_Fluency/Punctuation': 0.5502230634040828, 'A_Terminology/Inappropriate for context': 0.5142757660167131, 'A_Fluency/Grammar': 0.5607625099285147, 'A_Fluency/Inconsistency': 0.4612005856515373, 'A_Fluency/Spelling': 0.7769886363636364, 'A_Accuracy/Untranslated text': 0.4197031039136302, 'A_Accuracy/Addition': 0.6168224299065421, 'A_Fluency/Register': 0.5268817204301075, 'A_Terminology/Inconsistent use of terminology': 0.5862068965517242, 'A_Fluency/Display': 0.9347826086956522, 'A_Locale convention/Currency format': 0.641025641025641, 'A_Locale convention/Date format': 0.9230769230769231, 'A_Locale convention/Time format': 0.4722222222222222}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>A_No-error</th>\n",
       "      <th>A_Fluency/Punctuation</th>\n",
       "      <th>A_Style/Awkward</th>\n",
       "      <th>A_Accuracy/Mistranslation</th>\n",
       "      <th>A_Terminology/Inappropriate for context</th>\n",
       "      <th>A_Fluency/Grammar</th>\n",
       "      <th>A_Fluency/Inconsistency</th>\n",
       "      <th>A_Fluency/Spelling</th>\n",
       "      <th>A_Accuracy/Untranslated text</th>\n",
       "      <th>A_Accuracy/Addition</th>\n",
       "      <th>A_Fluency/Register</th>\n",
       "      <th>A_Terminology/Inconsistent use of terminology</th>\n",
       "      <th>A_Fluency/Display</th>\n",
       "      <th>A_Locale convention/Currency format</th>\n",
       "      <th>A_Locale convention/Date format</th>\n",
       "      <th>A_Locale convention/Time format</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T5 Large</td>\n",
       "      <td>49.354423</td>\n",
       "      <td>0.493544</td>\n",
       "      <td>0.488982</td>\n",
       "      <td>0.493953</td>\n",
       "      <td>0.480085</td>\n",
       "      <td>0.492340</td>\n",
       "      <td>0.513370</td>\n",
       "      <td>0.407028</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.760870</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FSMT WMT19 En-De</td>\n",
       "      <td>51.606327</td>\n",
       "      <td>0.516063</td>\n",
       "      <td>0.550223</td>\n",
       "      <td>0.502646</td>\n",
       "      <td>0.475189</td>\n",
       "      <td>0.514276</td>\n",
       "      <td>0.560763</td>\n",
       "      <td>0.461201</td>\n",
       "      <td>0.776989</td>\n",
       "      <td>0.419703</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>0.526882</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_name   accuracy  A_No-error  A_Fluency/Punctuation  \\\n",
       "0          T5 Large  49.354423    0.493544               0.488982   \n",
       "1  FSMT WMT19 En-De  51.606327    0.516063               0.550223   \n",
       "\n",
       "   A_Style/Awkward  A_Accuracy/Mistranslation  \\\n",
       "0         0.493953                   0.480085   \n",
       "1         0.502646                   0.475189   \n",
       "\n",
       "   A_Terminology/Inappropriate for context  A_Fluency/Grammar  \\\n",
       "0                                 0.492340           0.513370   \n",
       "1                                 0.514276           0.560763   \n",
       "\n",
       "   A_Fluency/Inconsistency  A_Fluency/Spelling  A_Accuracy/Untranslated text  \\\n",
       "0                 0.407028            0.656250                      0.461538   \n",
       "1                 0.461201            0.776989                      0.419703   \n",
       "\n",
       "   A_Accuracy/Addition  A_Fluency/Register  \\\n",
       "0             0.616822            0.387097   \n",
       "1             0.616822            0.526882   \n",
       "\n",
       "   A_Terminology/Inconsistent use of terminology  A_Fluency/Display  \\\n",
       "0                                       0.310345           0.760870   \n",
       "1                                       0.586207           0.934783   \n",
       "\n",
       "   A_Locale convention/Currency format  A_Locale convention/Date format  \\\n",
       "0                             0.256410                         0.923077   \n",
       "1                             0.641026                         0.923077   \n",
       "\n",
       "   A_Locale convention/Time format  \n",
       "0                         0.500000  \n",
       "1                         0.472222  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnd_mt_category = load_mt_mqm_nnd(label_type=\"category\")\n",
    "\n",
    "results = []\n",
    "for gen in gens:\n",
    "    model = GeneratorHF(**gen[\"model_params\"])\n",
    "    result = run_nnd(nnd_mt_category, model, gen[\"model_name\"], no_error_label=\"No-error\", report_type=\"accuracy\")\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/home/anaconda3/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:156: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n",
      "NND T5 Large: 100%|██████████| 42675/42675 [00:00<00:00, 568985.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'T5 Large', 'accuracy': 49.35442296426479, 'A_No-error': 0.49354422964264794, 'A_Minor': 0.5011370609681263, 'A_Major': 0.47949505744055565}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NND FSMT WMT19 En-De: 100%|██████████| 42675/42675 [00:02<00:00, 21018.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'FSMT WMT19 En-De', 'accuracy': 51.606326889279444, 'A_No-error': 0.5160632688927944, 'A_Major': 0.4873764360138926, 'A_Minor': 0.5315669783055987}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>A_No-error</th>\n",
       "      <th>A_Minor</th>\n",
       "      <th>A_Major</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T5 Large</td>\n",
       "      <td>49.354423</td>\n",
       "      <td>0.493544</td>\n",
       "      <td>0.501137</td>\n",
       "      <td>0.479495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FSMT WMT19 En-De</td>\n",
       "      <td>51.606327</td>\n",
       "      <td>0.516063</td>\n",
       "      <td>0.531567</td>\n",
       "      <td>0.487376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model_name   accuracy  A_No-error   A_Minor   A_Major\n",
       "0          T5 Large  49.354423    0.493544  0.501137  0.479495\n",
       "1  FSMT WMT19 En-De  51.606327    0.516063  0.531567  0.487376"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnd_mt_severity = load_mt_mqm_nnd(label_type=\"severity\")\n",
    "\n",
    "results = []\n",
    "for gen in gens:\n",
    "    model = GeneratorHF(**gen[\"model_params\"])\n",
    "    result = run_nnd(nnd_mt_severity, model, gen[\"model_name\"], no_error_label=\"No-error\", report_type=\"accuracy\")\n",
    "    print(result)\n",
    "    results.append(result)\n",
    "pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67c54bf5fb630355f694c741165b3bdb09e3b950d114a736855d00c72ee312e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
