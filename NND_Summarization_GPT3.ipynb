{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_nnd_dataset import load_summ_gpt3_nnd\n",
    "from utils_nnd import GeneratorHF, run_nnd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN/DM-like 3-sentence summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The annotations contain 205 sumamry pairs with a score gap of 2 or more.\n"
     ]
    }
   ],
   "source": [
    "nnd_summ_gpt3_3sent = load_summ_gpt3_nnd(dataset_type=\"cnn\", min_score_gap=2)\n",
    "print(\"The annotations contain %d sumamry pairs with a score gap of 2 or more.\" % len(nnd_summ_gpt3_3sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-22 14:34:59,067] [WARNING] [partition_parameters.py:53:<module>] unable to find torch.distributed._all_gather_base. will fall back to torch.distributed.all_gather which will result in suboptimal performance. please consider upgrading your pytorch installation.\n"
     ]
    }
   ],
   "source": [
    "summarizers = [\n",
    "    {\"model_name\": \"BART-L\", \"model\": GeneratorHF(model_card=\"facebook/bart-large-cnn\")},\n",
    "    {\"model_name\": \"PEGASUS\", \"model\": GeneratorHF(model_card=\"google/pegasus-cnn_dailymail\")},\n",
    "    {\"model_name\": \"BRIO\", \"model\": GeneratorHF(model_card=\"Yale-LILY/brio-cnndm-cased\")},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NND BART-L: 100%|██████████| 205/205 [00:12<00:00, 16.17it/s]\n",
      "NND PEGASUS: 100%|██████████| 205/205 [00:15<00:00, 12.92it/s]\n",
      "NND BRIO: 100%|██████████| 205/205 [00:12<00:00, 17.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name  accuracy  A_nopass  A_success\n",
      "0     BART-L       0.0  0.546341   0.453659\n",
      "1    PEGASUS       0.0  0.585366   0.414634\n",
      "2       BRIO       0.0  0.424390   0.575610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = [run_nnd(nnd_summ_gpt3_3sent, summ[\"model\"], summ[\"model_name\"], no_error_label=\"no error\", report_type=\"accuracy\") for summ in summarizers]\n",
    "with pd.option_context('display.max_rows', 300, 'display.max_columns', 7, 'display.expand_frame_repr', False):\n",
    "    print(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XSum-like 1-sentence summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The annotations contain 208 sumamry pairs with a score gap of 2 or more.\n"
     ]
    }
   ],
   "source": [
    "nnd_summ_gpt3_1sent = load_summ_gpt3_nnd(dataset_type=\"bbc\", min_score_gap=2)\n",
    "print(\"The annotations contain %d sumamry pairs with a score gap of 2 or more.\" % len(nnd_summ_gpt3_1sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizers = [\n",
    "    {\"model_name\": \"BART-L\", \"model\": GeneratorHF(model_card=\"facebook/bart-large-xsum\")},\n",
    "    {\"model_name\": \"PEGASUS\", \"model\": GeneratorHF(model_card=\"google/pegasus-xsum\")},\n",
    "    # {\"model_name\": \"BRIO\", \"model\": GeneratorHF(model_card=\"Yale-LILY/brio-xsum-cased\")},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NND BART-L: 100%|██████████| 208/208 [00:12<00:00, 17.24it/s]\n",
      "NND PEGASUS: 100%|██████████| 208/208 [00:15<00:00, 13.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  model_name  accuracy  A_success  A_nopass\n",
      "0     BART-L       0.0   0.514423  0.485577\n",
      "1    PEGASUS       0.0   0.567308  0.432692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = [run_nnd(nnd_summ_gpt3_1sent, summ[\"model\"], summ[\"model_name\"], no_error_label=\"no error\", report_type=\"accuracy\") for summ in summarizers]\n",
    "with pd.option_context('display.max_rows', 300, 'display.max_columns', 7, 'display.expand_frame_repr', False):\n",
    "    print(pd.DataFrame(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "67c54bf5fb630355f694c741165b3bdb09e3b950d114a736855d00c72ee312e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
